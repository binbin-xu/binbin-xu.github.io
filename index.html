<html>

<head>
  <title>BINBIN XU</title>

  <script src="//use.edgefonts.net/open-sans:n3,i3,n4,i4,n6,i6,n7,i7,n8,i8.js"></script>
  <script src="//use.edgefonts.net/open-sans-condensed:n3,i3,n7.js"></script>
  <script src="//use.edgefonts.net/league-gothic:n4.js"></script>

  <link rel="stylesheet" type="text/css" href="css/main.css">

  <script LANGUAGE="JavaScript">
    // Set up the image files to be used.
    var theImages = new Array() // do not change this
    // To add more image files, continue with the
    // pattern below, adding to the array.

    theImages[0] = 'profile/binbin_photo.gif'
    theImages[1] = 'profile/binbin_photo1.jpeg'
    theImages[2] = 'profile/binbin_photo2.jpg'
    theImages[3] = 'profile/binbin_photo3.jpeg'
    theImages[4] = 'profile/binbin_photo4.jpeg'
    theImages[5] = 'profile/binbin_photo5.JPG'

    // do not edit anything below this line

    var j = 0
    var p = theImages.length;
    var preBuffer = new Array()
    for (i = 0; i < p; i++) {
      preBuffer[i] = new Image()
      preBuffer[i].src = theImages[i]
    }
    var whichImage = Math.floor(Math.random() * (p));
    function showImage() {
      document.write('<img style="float:right; border: #404040 1px solid;" alt="Binbin photo" height = "250" src="' + theImages[whichImage] + '"');
    }

//  End -->
  </script>

</head>

<body>

  <div class="main_container">
    <div class="content_container">

<div style="padding-top: 5px">
    <script type="text/javascript" language="JavaScript">
      showImage();
    </script>
    <img style="float:right; border: #404040 1px solid;" src="profile/binbin_photo.gif" height="225"
      alt="Binbin photo" />
    <div class="title_text">
      <div>BINBIN XU</div>
    </div>
    <div class="minor_text" style="padding-top: 10px;">
      <div>Staff Researcher</div>
      <div>HUAWEI Noah's Ark Lab Canada</div>
      <div><img src="images/outlook_email.png" width="240" style="padding: 5px 0px 2px 0px;" alt="Contact Info" />
      </div>
    </div>
    <div class="minor_text" style="padding-top: 10px;">
      <a href="data/Binbin_Xu_Resume.pdf">CV</a> / <a
        href="https://scholar.google.co.jp/citations?user=874PofoAAAAJ&hl=en">Google
        Scholar</a> / <a href="https://www.linkedin.com/in/binbinxu91/">LinkedIn</a> / Blog
    </div>
  </div>


  <div style="clear:both;"></div>

  <div style="padding-top: 25px;" class="splash">

    <!-- <div style="padding: 5px 0px 5px 0px">
      
    </div> -->

    <div style="padding: 10px 0px 0px 0px;">

      My core research interest focuses on achieveing <span class="emphblack">a robust and accurate object-level SLAM system that works
        in dynamic environments and can continously update and maintain its status</span>. 
        Such higher level object-level perception enables robots to perform more complex tasks in a more efficient and reliable way. 
        My interests expand to its applications in robotics, scene understanding and spatial AI. 
    </div>
    <div>
      Please feel free to contact me if you are interested in discussing these topics with me.
    </div>

    <div class="subtitle_text">Brief Bio</div>

    <div style="padding: 20px 0px 0px 0px;">
      I am currently a staff researcher at HUAWEI Noah's Ark Lab Canada, working on Autonomous Driving and Embodied AI.
    </div>
    <div>
      I obtained my PhD at Imperial College London (<a
        href="https://spiral.imperial.ac.uk/handle/10044/1/101244">PhD thesis</a>) in 2022, supervised by <a
        href="http://wp.doc.ic.ac.uk/sleutene/about/">Prof.
        Stefan Leutenegger</a> and <a href="https://www.doc.ic.ac.uk/~ajd/">Prof. Andrew Davison</a>.
      Follwoing that, I worked as a Postdoc fellow in the <a href="http://asrl.utias.utoronto.ca/">Autonomous Space
        Robotics Lab (ASRL)</a> of University of Toronto with <a href="http://asrl.utias.utoronto.ca/~tdb/">Prof.
        Tim Barfoot</a>.
      I received my Master degree in Precision Engineering from
      the University of Tokyo in 2017, supervised by <a
        href="http://www.robot.t.u-tokyo.ac.jp/~yamashita/index.html">
        Prof. Atsushi Yamashita</a> and <a
        href="http://www.robot.t.u-tokyo.ac.jp/asamalab/Asama_page/top_a.html">Prof.
        Hajime Asama</a>. I got my Bachelor's degree in Information Engineering from South China
      University of Technology in 2014. <!-- I also did a <a href="https://arxiv.org/abs/2109.15299">research 
        internship</a> at Facebook Reality Labs with Dr. Lingni Ma during my PhD.-->
    </div>


    <div class="subtitle_text">SELECTED <a
        href="https://scholar.google.co.jp/citations?user=874PofoAAAAJ&hl=en">PUBLICATIONS</a></div>

        <div style="padding-top: 20px;">
          <table width="100%" style="font-family:open-sans,sans-serif;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;


" align="middle" border="0" cellspacing="0" cellpadding="0">
<tr>
<td style="padding:10px;width:25%;vertical-align:middle"><img
src="pub/corl2025/unpose.jpg" width="97%"
style="border-style: none">
</td>
<td style="padding:5px;width:75%;vertical-align:middle">
<b><span class="papertitle">UnPose: Uncertainty-Guided Diffusion Priors for Zero-Shot Pose Estimation</span></b>
<br>
<a href="https://scholar.google.ca/citations?user=ISNrsywAAAAJ&hl=en&oi=sra">Zhaodong Jiang</a>, <a href="https://sinashish.github.io/">Ashish Sinha</a>, <a href="https://scholar.google.com/citations?user=SkzzXSYAAAAJ&hl=en">Tongtong Cao</a>, <a href="https://scholar.google.com/citations?user=P4Rp5uAAAAAJ&hl=en">Yuan Ren</a>, <a href="https://scholar.google.ca/citations?user=-rCulKwAAAAJ&hl=en">Bingbing Liu</a>, <b>Binbin Xu</b>
<br>
<em>Conference on Robot Learning (CoRL)</em>, 2025
<br>
<a href="https://frankzhaodong.github.io/UnPose"> project</a> /
<a href="https://openreview.net/forum?id=L5PJBd8ahD#discussion"> OpenReview</a> /
<!-- <a href=""> arXiv</a>  -->
</td>
</tr>

<div style="padding-top: 20px;">
          <table width="100%" style="font-family:open-sans,sans-serif;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;
" align="middle" border="0" cellspacing="0" cellpadding="0">
<tr>
<td style="padding:10px;width:25%;vertical-align:middle"><img
src="pub/ral2025/hippo.gif" width="97%"
style="border-style: none">
</td>
<td style="padding:5px;width:75%;vertical-align:middle">
<b><span class="papertitle">Hippo: Harnessing image-to-3d priors for model-free zero-shot 6d pose estimation</span></b>
<br>
<a href="https://yorklyb.github.io/">Yibo Liu</a>, <a href="https://scholar.google.ca/citations?user=ISNrsywAAAAJ&hl=en&oi=sra">Zhaodong Jiang</a>, <b>Binbin Xu</b>, <a href="https://guilewu.github.io/">Guile Wu</a>, <a href="https://scholar.google.com/citations?user=P4Rp5uAAAAAJ&hl=en">Yuan Ren</a>, <a href="https://scholar.google.com/citations?user=SkzzXSYAAAAJ&hl=en">Tongtong Cao</a>, <a href="https://scholar.google.ca/citations?user=-rCulKwAAAAJ&hl=en">Bingbing Liu</a>, <a href="https://www.linkedin.com/in/rhyang6/?originalSubdomain=ca">Rui Heng Yang</a>, <a href="https://aras62.github.io/">Amir Rasouli</a>, <a href="https://www.yorku.ca/jjshan/PROF_SHAN.html">Jinjun Shan</a>
<br>
<em>IEEE Robotics and Automation Letters</em>, 2025 (ICRA 2026 presentation)
<br>
<a href="https://hippope.github.io/"> project</a> /
<a href="https://ieeexplore.ieee.org/document/11063421"> paper</a> /
<a href="https://arxiv.org/pdf/2502.10606"> arXiv</a>
</td>
</tr>

<div style="padding-top: 20px;">
          <table width="100%" style="font-family:open-sans,sans-serif;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;


" align="middle" border="0" cellspacing="0" cellpadding="0">
<tr>
<td style="padding:10px;width:25%;vertical-align:middle"><img
src="pub/corl2024/GenenicMapping.png" width="97%"
style="border-style: none">
</td>
<td style="padding:5px;width:75%;vertical-align:middle">
<b><span class="papertitle">Toward General Object-level Mapping from Sparse Views with 3D Diffusion Priors</span></b>
<br>
<a href="https://ziwei-liao.github.io/"> Ziwei Liao</a>  , <b>Binbin Xu</b>, <a href="https://www.trailab.utias.utoronto.ca/stevenwaslander"> Steven L. Waslander</a>
<br>
<em>Conference on Robot Learning (CoRL)</em>, 2024
<br>
 <a href="https://arxiv.org/abs/2410.05514"> arXiv</a> /
<a href="https://openreview.net/forum?id=rEteJcq61j"> OpenReview</a>
/ <a href="https://github.com/TRAILab/GeneralObjectMapping"> code</a>
</td>
</tr>

<div style="padding-top: 20px;">
          <table width="100%" style="font-family:open-sans,sans-serif;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;
" align="middle" border="0" cellspacing="0" cellpadding="0">
<tr>
<td style="padding:10px;width:25%;vertical-align:middle"><img
src="pub/iros2024/balloon.png" width="97%"
style="border-style: none">
</td>
<td style="padding:5px;width:75%;vertical-align:middle">
<b><span class="papertitle">Identifying Optimal Launch Sites of High-Altitude Latex-Balloons using Bayesian Optimisation for the Task of Station-Keeping</span></b>
<br>
<a href="https://www.saundersj.dev/">Jack Saunders</a>,
<a href="https://sajad-saeedi.ca/">Sajad Saeedi</a>,
Adam Hartshorne, <b>Binbin Xu</b>, Özgur Şimşek, Alan Hunter,
<a href="https://wbli.me/">Wenbin Li</a>
<br>
<em>IEEE/RSJ International Conference on Intelligent Robots and Systems
(IROS)</em>, 2024
<br>
<a href="https://sites.google.com/view/bo-lauch-balloon/home"> project</a> /
<a href="https://ieeexplore.ieee.org/document/10802275"> paper</a> /
<a href="https://arxiv.org/pdf/2403.10784.pdf"> arXiv</a> /
<!-- <a href="mailto: b.xu17@imperial.ac.uk"> code</a> / -->
<a href="https://youtu.be/AVvRldktVCk"> video</a> /
<!-- <a href="https://scholar.google.co.jp/citations?view_op=view_citation&hl=en&user=874PofoAAAAJ&sortby=pubdate&citation_for_view=874PofoAAAAJ:eQOLeE2rZwMC"
aria-label="Google Scholar link" role="button"
rel="external nofollow noopener" target="_blank"> -->
<!-- <img
src="https://img.shields.io/badge/scholar-9-4285F4?logo=googlescholar&labelColor=beige"
alt="9 Google Scholar citations"> </a> -->
</td>
</tr>

<div style="padding-top: 20px;">
      <table width="100%" style="font-family:open-sans,sans-serif;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;
      " align="middle" border="0" cellspacing="0" cellpadding="0">
        <tr>
          <td style="padding:10px;width:25%;vertical-align:middle"><img src="pub/ral2024_mose/mose.jpg"
          width="97%" style="border-style: none"></td>
          <td style="padding:5px;width:75%;vertical-align:middle">
            <b><span class="papertitle">MOSE: Monocular Semantic Reconstruction Using NeRF-Lifted Noisy Priors
              </span></b>
            <br>
            Zhenhua Du, <b>Binbin Xu</b>, Haoyu Zhang, Kai Huo, <a href="https://shuaifengzhi.com/">Shuaifeng Zhi</a> 
            <br>
            <em>IEEE Robotics and Automation Letters</em>, 2024
            <br>
            <a href="https://ieeexplore.ieee.org/document/10685078"> paper</a> /
            <a href="https://arxiv.org/pdf/2409.14019"> arXiv</a> /
            <!-- <a href="https://www.youtube.com/watch?v=El3-hSnuOz0"> video</a> / -->
            <a href="https://github.com/ZhenhuaDu11/Mose"> code</a> 
            <!-- <a href="https://scholar.google.co.jp/citations?view_op=view_citation&hl=en&user=874PofoAAAAJ&sortby=pubdate&citation_for_view=874PofoAAAAJ:Se3iqnhoufwC"
              aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank">
              <img src="https://img.shields.io/badge/scholar-7-4285F4?logo=googlescholar&labelColor=beige"
                alt="7 Google Scholar citations"> </a> -->
          </td>
        </tr>
                
                
    <div style="padding-top: 20px;">
      <table width="100%" style="font-family:open-sans,sans-serif;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;
      " align="middle" border="0" cellspacing="0" cellpadding="0">
        <tr>
          <td style="padding:10px;width:25%;vertical-align:middle"><img src="pub/ral2024_nerfVO/2024nerfvo.gif"
          width="97%" style="border-style: none"></td>
          <td style="padding:5px;width:75%;vertical-align:middle">
            <b><span class="papertitle">NeRF-VO: Real-Time Sparse Visual Odometry with Neural Radiance Fields
              </span></b>
            <br>
            <a href="https://www.linkedin.com/in/jens-naumann/">Jens Naumann</a>, 
            <b>Binbin Xu</b>, 
            <a href="https://www.professoren.tum.de/en/leutenegger-stefan">Stefan Leutenegger</a>, 
            <a href="https://xingxingzuo.github.io/">Xingxing Zuo</a>
            <br>
            <em>IEEE Robotics and Automation Letters</em>, 2024
            <br>
            <a href="https://xingxingzuo.github.io/nerfvo/"> project</a> /
            <a href="https://ieeexplore.ieee.org/document/10578010"> paper</a> /
            <a href="https://arxiv.org/pdf/2312.13471"> arXiv</a> /
            <a href="https://www.youtube.com/watch?v=El3-hSnuOz0"> video</a> /
            <a href="https://github.com/jens-nau/NeRF-VO"> code</a>
            <!-- <a href="https://scholar.google.co.jp/citations?view_op=view_citation&hl=en&user=874PofoAAAAJ&sortby=pubdate&citation_for_view=874PofoAAAAJ:Se3iqnhoufwC"
              aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank">
              <img src="https://img.shields.io/badge/scholar-7-4285F4?logo=googlescholar&labelColor=beige"
                alt="7 Google Scholar citations"> </a> -->
          </td>
        </tr>

        <div style="padding-top: 20px;">
          <table width="100%" style="font-family:open-sans,sans-serif;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;
          " align="middle" border="0" cellspacing="0" cellpadding="0">
            <tr>
              <td style="padding:10px;width:25%;vertical-align:middle"><img src="pub/safethings/x_mvp.png"
              <!-- width="97%" style="border-style: none"></td> 
              <td style="padding:5px;width:75%;vertical-align:middle">
                <b><span class="papertitle">Adversarial 3D Virtual Patches using Integrated Gradients
                  </span></b>
                <br>
                <a href="https://scholar.google.com/citations?user=dkaoGoMAAAAJ&hl=en">Chengzeng You</a>, 
                Zhongyuan Hau, 
                <b>Binbin Xu</b>, 
                <a href="https://soteris.github.io/">Soteris Demetriou</a>, 
                <br>
                <em>IEEE/ACM Workshop on the Internet of Safe Things, co-located with IEEE Symposium on Security and
                  Privacy (S&P) </em>, 2024
                <br>
                <b style="color:#FF0000" ;>Best Paper Award</b>
                <br>
                <!-- <a href="https://www.youtube.com/watch?v=Ip-XmInVlwU"> project</a> / -->
                <a href="https://sp2024.ieee-security.org/downloads/SP24-posters/sp24posters-final1.pdf"> paper</a> /
                <a href="https://arxiv.org/pdf/2406.00282"> arXiv</a> 
                <!-- <a href="https://www.youtube.com/watch?v=bY6zffvbSGE"> video</a>  --> 
                <!-- <a style="color:#00aaff"; href="https://github.com/chutsu/yac"> code</a> -->
                <!-- <a href="https://scholar.google.co.jp/citations?view_op=view_citation&hl=en&user=874PofoAAAAJ&sortby=pubdate&citation_for_view=874PofoAAAAJ:0EnyYjriUFMC"
                  aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank">
                  <img src="https://img.shields.io/badge/scholar-0-4285F4?logo=googlescholar&labelColor=beige"
                    alt="0 Google Scholar citations"> </a> -->
              </td>
            </tr>

            <div style="padding-top: 20px;">
              <table width="100%" style="font-family:open-sans,sans-serif;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;
      " align="middle" border="0" cellspacing="0" cellpadding="0">
                <tr>
                  <td style="padding:10px;width:25%;vertical-align:middle"><img src="pub/icra2024/funcgrasp.gif"
                      width="97%" style="border-style: none"></td>
                  <td style="padding:5px;width:75%;vertical-align:middle">
                    <b><span class="papertitle">FuncGrasp: Learning Object-Centric Neural Grasp Functions from
                        Single
                        Annotated Example Object</span></b>
                    <br>
                    <a href="https://hanzhic.github.io/">Hanzhi Chen</a>, 
                    <b>Binbin Xu</b>, 
                    <a href="https://www.professoren.tum.de/en/leutenegger-stefan">Stefan Leutenegger</a>
                    <br>
                    <em>IEEE International Conference on Robotics and Automation (ICRA)</em>, 2024
                    <br>
                    <a href="https://hanzhic.github.io/"> project</a> /
                    <a href="https://ieeexplore.ieee.org/document/10611233"> paper</a> /
                    <a href="https://arxiv.org/pdf/2402.05644"> arXiv</a> /
                    <a href="https://www.youtube.com/watch?v=sZ0u2ZpgpNc"> video</a> 
                    <!-- <a style="color:#00aaff"; href="https://github.com/smartroboticslab/semantic-exploration-icra-2023"> code</a> -->
                    <!-- <a href="https://scholar.google.co.uk/citations?view_op=view_citation&hl=en&user=874PofoAAAAJ&sortby=pubdate&citation_for_view=874PofoAAAAJ:UebtZRa9Y70C"
                      aria-label="Google Scholar link" role="button" rel="external nofollow noopener"
                      target="_blank">
                      <img src="https://img.shields.io/badge/scholar-1-4285F4?logo=googlescholar&labelColor=beige"
                        alt="1 Google Scholar citations"> </a> -->
                  </td>
                </tr>

                <div style="padding-top: 20px;">
                  <table width="100%" style="font-family:open-sans,sans-serif;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;
          " align="middle" border="0" cellspacing="0" cellpadding="0">
                    <tr>
                      <td style="padding:10px;width:25%;vertical-align:middle"><img src="pub/ral2023/2023fvfusion.png" width="97%" style="border-style: none"></td> 
                      <td style="padding:5px;width:75%;vertical-align:middle">
                        <b><span class="papertitle">Incremental Dense Reconstruction from Monocular Video with
                            Guided
                            Sparse Feature Volume Fusion
                          </span></b>
                        <br>
                        <a href="https://xingxingzuo.github.io/">Xingxing Zuo</a>, 
                        <a href="https://nan-yang.me/">Nan Yang</a>, 
                        <a href="https://udel.edu/~nmerrill/">Nathaniel Merrill</a>, 
                        <b>Binbin Xu</b>, 
                        <a href="https://www.professoren.tum.de/en/leutenegger-stefan">Stefan Leutenegger</a>
                        <br>
                        <em>IEEE Robotics and Automation Letters</em>, 2023
                        <br>
                        <!-- <a href="https://xingxingzuo.github.io/nerfvo/"> project</a> / -->
                        <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10120911">
                          paper</a> /
                        <a href="https://arxiv.org/pdf/2305.14918"> arXiv</a> /
                        <a href="https://www.youtube.com/watch?v=bY6zffvbSGE"> video</a> 
                        <!-- <a style="color:#00aaff"; href="https://github.com/jens-nau/NeRF-VO"> code</a> -->
                        <!-- <a href="https://scholar.google.co.jp/citations?view_op=view_citation&hl=en&user=874PofoAAAAJ&sortby=pubdate&citation_for_view=874PofoAAAAJ:_FxGoFyzp5QC"
                          aria-label="Google Scholar link" role="button" rel="external nofollow noopener"
                          target="_blank">
                          <img
                            src="https://img.shields.io/badge/scholar-2-4285F4?logo=googlescholar&labelColor=beige"
                            alt="2 Google Scholar citations"> </a> -->
                      </td>
                    </tr>

                    <div style="padding-top: 20px;">
                      <table width="100%" style="font-family:open-sans,sans-serif;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;
          " align="middle" border="0" cellspacing="0" cellpadding="0">
                        <tr>
                          <td style="padding:10px;width:25%;vertical-align:middle"><img src="pub/iros2023_yac/yac_calib.jpg" width="95%" style="border-style: none"></td> 
                          <td style="padding:5px;width:75%;vertical-align:middle">
                            <b><span class="papertitle">Accurate and Interactive Visual-Inertial Sensor Calibration
                                with
                                Next-Best-View and Next-Best-Trajectory Suggestion
                              </span></b>
                            <br>
                            <a href="https://chutsu.github.io/">Christopher L Choi</a>, 
                            <b>Binbin Xu</b>, 
                            <a href="https://www.professoren.tum.de/en/leutenegger-stefan">Stefan Leutenegger</a>
                            <br>
                            <em>IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</em>,
                            2023
                            <br>
                            <a href="https://www.youtube.com/watch?v=Ip-XmInVlwU"> project</a> /
                            <a href="https://ieeexplore.ieee.org/abstract/document/10341815">
                              paper</a> /
                            <a href="https://arxiv.org/pdf/2309.14514"> arXiv</a> /
                            <a href="https://www.youtube.com/watch?v=2vaas9NYlOk"> video</a> /
                            <a href="https://github.com/chutsu/yac"> code</a> 
                            <!-- <a href="https://scholar.google.co.jp/citations?view_op=view_citation&hl=en&user=874PofoAAAAJ&sortby=pubdate&citation_for_view=874PofoAAAAJ:roLk4NBRz8UC"
                              aria-label="Google Scholar link" role="button" rel="external nofollow noopener"
                              target="_blank">
                              <img
                                src="https://img.shields.io/badge/scholar-0-4285F4?logo=googlescholar&labelColor=beige"
                                alt="0 Google Scholar citations"> </a> -->
                          </td>
                        </tr>

                        <div style="padding-top: 20px;">
                          <table width="100%" style="font-family:open-sans,sans-serif;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;
              " align="middle" border="0" cellspacing="0" cellpadding="0">
                            <tr>
                              <td style="padding:10px;width:25%;vertical-align:middle"><img src="pub/iros2023_feature/feature_learning.jpg" width="97%" style="border-style: none"></td> 
                              <td style="padding:5px;width:75%;vertical-align:middle">
                                <b><span class="papertitle">What to learn: Features, image transformations, or both?
                                  </span></b>
                                <br>
                                <a href="https://www.linkedin.com/in/sherry-chen-engsci127/">Yuxuan Chen</a>,
                                <b>Binbin Xu</b>, 
                                <a href="https://duembgen.github.io/">Frederike Dümbgen</a>,
                                <a href="http://asrl.utias.utoronto.ca/~tdb/">Timothy D Barfoot</a>
                                <br>
                                <em>IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</em>,
                                2023
                                <br>
                                <!-- <a href="https://www.youtube.com/watch?v=Ip-XmInVlwU"> project</a> / -->
                                <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10342415"> paper</a> /
                                <a href="https://arxiv.org/pdf/2306.13040"> arXiv</a> /
                                <a href="https://www.youtube.com/watch?v=XNSdRMUqGvA"> video</a> 
                                <!-- <a style="color:#00aaff"; href="https://github.com/chutsu/yac"> code</a> -->
                                <!-- <a href="https://scholar.google.co.jp/citations?view_op=view_citation&hl=en&user=874PofoAAAAJ&sortby=pubdate&citation_for_view=874PofoAAAAJ:LkGwnXOMwfcC"
                                  aria-label="Google Scholar link" role="button" rel="external nofollow noopener"
                                  target="_blank">
                                  <img
                                    src="https://img.shields.io/badge/scholar-1-4285F4?logo=googlescholar&labelColor=beige"
                                    alt="1 Google Scholar citations"> </a> -->
                              </td>
                            </tr>

                            <div style="padding-top: 20px;">
                              <table width="100%" style="font-family:open-sans,sans-serif;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;
      " align="middle" border="0" cellspacing="0" cellpadding="0">
                                <tr>
                                  <td style="padding:10px;width:25%;vertical-align:middle"><img
                                      src="pub/icra2023/semanticeight.gif" width="97%" style="border-style: none">
                                  </td>
                                  <td style="padding:5px;width:75%;vertical-align:middle">
                                    <b><span class="papertitle">Finding Things in the Unknown: Semantic
                                        Object-Centric
                                        Exploration
                                        with an MAV</span></b>
                                    <br>
                                    <a href="https://sotiris.papatheodorou.xyz/">Sotiris Papatheodorou</a>,  
                                    Nils Funk, 
                                    <a href="https://scholar.google.com/citations?user=6AKGwQsAAAAJ&hl=en/">Dimos Tzoumanikas</a>,  
                                    <a href="https://chutsu.github.io/">Christopher Choi</a>, 
                                    <b>Binbin Xu</b>, 
                                    <a href="https://www.professoren.tum.de/en/leutenegger-stefan">Stefan Leutenegger</a>
                                    <br>
                                    <em>IEEE International Conference on Robotics and Automation (ICRA)</em>, 2023
                                    <br>
                                    <a href="https://github.com/smartroboticslab/semantic-exploration-icra-2023">
                                      project</a> /
                                    <a href="https://ieeexplore.ieee.org/document/10160490">
                                      paper</a> /
                                    <a href="https://arxiv.org/pdf/2302.14569.pdf"> arXiv</a> /
                                    <a href="https://www.youtube.com/watch?v=z0LVe_8SATU"> video</a> /
                                    <a href="https://github.com/smartroboticslab/semantic-exploration-icra-2023">
                                      code</a> 
                                    <!-- <a href="https://scholar.google.co.jp/citations?view_op=view_citation&hl=en&user=874PofoAAAAJ&sortby=pubdate&citation_for_view=874PofoAAAAJ:ufrVoPGSRksC"
                                      aria-label="Google Scholar link" role="button"
                                      rel="external nofollow noopener" target="_blank">
                                      <img
                                        src="https://img.shields.io/badge/scholar-5-4285F4?logo=googlescholar&labelColor=beige"
                                        alt="5 Google Scholar citations"> </a> -->
                                  </td>
                                </tr>

                                <div style="padding-top: 20px;">
                                  <table width="100%" style="font-family:open-sans,sans-serif;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;
      " align="middle" border="0" cellspacing="0" cellpadding="0">
                                    <tr>
                                      <td style="padding:10px;width:25%;vertical-align:middle"><img
                                          src="pub/iros2022/iros2022_chair_completion.jpg" width="97%"
                                          style="border-style: none">
                                      </td>
                                      <td style="padding:5px;width:75%;vertical-align:middle">
                                        <b><span class="papertitle">Learning to Complete Object Shapes for
                                            Object-level
                                            Mapping in
                                            Dynamic Scenes</span></b>
                                        <br>
                                        <b>Binbin Xu</b>, 
                                        <a href="https://www.doc.ic.ac.uk/~ajd/">Andrew J. Davison</a>, 
                                        <a href="https://www.professoren.tum.de/en/leutenegger-stefan">Stefan Leutenegger</a>
                                        <br>
                                        <em>IEEE/RSJ International Conference on Intelligent Robots and Systems
                                          (IROS)</em>, 2022
                                        <br>
                                        <a href="https://mlr.in.tum.de/research/projects/cosom"> project</a> /
                                        <a href="https://ieeexplore.ieee.org/document/9981545">
                                          paper</a> /
                                        <a href="https://arxiv.org/pdf/2208.05067.pdf"> arXiv</a> /
                                        <!-- <a href="mailto: b.xu17@imperial.ac.uk"> code</a> / -->
                                        <a href="https://youtu.be/mH22H7jp1D8"> video</a> 
                                        <!-- <a href="https://scholar.google.co.jp/citations?view_op=view_citation&hl=en&user=874PofoAAAAJ&sortby=pubdate&citation_for_view=874PofoAAAAJ:eQOLeE2rZwMC"
                                          aria-label="Google Scholar link" role="button"
                                          rel="external nofollow noopener" target="_blank">
                                          <img
                                            src="https://img.shields.io/badge/scholar-9-4285F4?logo=googlescholar&labelColor=beige"
                                            alt="9 Google Scholar citations"> </a> -->
                                      </td>
                                    </tr>

                                    <tr>
                                      <td style="width:25%;vertical-align:middle"><img
                                          src="pub/iros2022_vimid/vimid_factor.jpg" width="97%"
                                          style="border-style: none"></td>
                                      <td style="padding:5px;width:75%;vertical-align:middle">
                                        <b><span class="papertitle">Visual-Inertial Multi-Instance Dynamic SLAM with
                                            Object-level
                                            Relocalisation</span></b>
                                        <br>
                                        <a href="https://scholar.google.com/citations?user=-LGAc6sAAAAJ">Yifei Ren*</a>,
                                        <b>Binbin Xu*</b>, 
                                        <a href="https://chutsu.github.io/">Christopher L Choi</a>,  
                                        <a href="https://www.professoren.tum.de/en/leutenegger-stefan">Stefan Leutenegger</a>
                                        <br>
                                        <em>IEEE/RSJ International Conference on Intelligent Robots and Systems
                                          (IROS)</em>, 2022
                                        <br>
                                        <a href="https://mlr.in.tum.de/research/projects/vimid"> project</a> /
                                        <a href="https://ieeexplore.ieee.org/document/9981795">
                                          paper</a> /
                                        <a href="https://arxiv.org/pdf/2208.04274.pdf"> arXiv</a> /
                                        <a href="https://youtu.be/6GY5cBwvuJE"> video</a> /
                                        <a href="https://github.com/smartroboticslab/vimid">
                                          code</a> 
                                        <!-- <a href="https://scholar.google.co.jp/citations?view_op=view_citation&hl=en&user=874PofoAAAAJ&sortby=pubdate&citation_for_view=874PofoAAAAJ:YsMSGLbcyi4C"
                                          aria-label="Google Scholar link" role="button"
                                          rel="external nofollow noopener" target="_blank">
                                          <img
                                            src="https://img.shields.io/badge/scholar-11-4285F4?logo=googlescholar&labelColor=beige"
                                            alt="11 Google Scholar citations"> </a> -->
                                      </td>
                                    </tr>

                                    <tr>
                                      <td width="25%"><img src="pub/ral2020/ral2020.gif" width="97%"
                                          style="border-style: none">
                                      </td>
                                      <td style="padding:5px;width:75%;vertical-align:middle">
                                        <b><span class="papertitle">Deep Probabilistic Feature-metric
                                            Tracking</span></b>
                                        <br>
                                        <b>Binbin Xu</b>, <a href="https://www.doc.ic.ac.uk/~ajd/">Andrew J. Davison</a>, <a href="https://www.professoren.tum.de/en/leutenegger-stefan">Stefan Leutenegger</a>
                                        <br>
                                        <em>IEEE Robotics and Automation Letters (RA-L), Vol. 6, No. 1, pp.
                                          223-230</em>, 2021 (ICRA
                                        2021 presentation)
                                        <br>
                                        <b style="color:#FF0000" ;>Honorable Mention of RA-L 2021 Best Paper
                                          Award</b>
                                        <br>
                                        <a href="https://ieeexplore.ieee.org/document/9264717">
                                          paper</a> /
                                        <a href="https://arxiv.org/pdf/2008.13504.pdf"> arXiv</a> /
                                        <a href="https://youtu.be/6pMosl6ZAPE"> video</a> /
                                        <a href="https://github.com/smartroboticslab/deep_prob_feature_track">
                                          code</a> 
                                        <!-- <a href="https://scholar.google.co.jp/citations?view_op=view_citation&hl=en&user=874PofoAAAAJ&sortby=pubdate&citation_for_view=874PofoAAAAJ:zYLM7Y9cAGgC"
                                          aria-label="Google Scholar link" role="button"
                                          rel="external nofollow noopener" target="_blank">
                                          <img
                                            src="https://img.shields.io/badge/scholar-15-4285F4?logo=googlescholar&labelColor=beige"
                                            alt="15 Google Scholar citations"> </a> -->
                                      </td>
                                    </tr>

                                    <tr>
                                      <td width="25%"><img src="pub/icra2019/midfusion.gif" width="97%"
                                          style="border-style: none">
                                      </td>
                                      <td style="padding:5px;width:75%;vertical-align:middle">
                                        <b><span class="papertitle">MID-Fusion: Octree-based Object-Level
                                            Multi-Instance
                                            Dynamic
                                            SLAM</span></b>
                                        <br>
                                        <b>Binbin Xu</b>, 
                                        <a href="https://wbli.me/">Wenbin Li</a>, 
                                        <a href="https://scholar.google.com/citations?user=6AKGwQsAAAAJ&hl=en/">Dimos Tzoumanikas</a>, 
                                        <a href="https://scholar.google.co.jp/citations?user=fn6GhgoAAAAJ&hl=en/">Michael Bloesch</a>, 
                                        <a href="https://www.doc.ic.ac.uk/~ajd/">Andrew Davison</a>,
                                        <a href="https://www.professoren.tum.de/en/leutenegger-stefan">Stefan Leutenegger</a>
                                        <br>
                                        <em>IEEE International Conference on Robotics and Automation (ICRA)</em>,
                                        2019
                                        <br>
                                        <a href="https://ieeexplore.ieee.org/document/8794371">
                                          paper</a> /
                                        <a href="https://arxiv.org/pdf/1812.07976.pdf"> arXiv</a> /
                                        <a href="https://youtu.be/gturboNl9gg">video</a> /
                                        <a href="pub/icra2019/rgb-tracker.pdf"> rgb-jacobian</a> /
                                        <a
                                          href="https://drive.google.com/drive/folders/1DmqX59qw_U6YsmkY9aZfZ5y0Dt65N_1x?usp=sharing">
                                          data</a> /
                                        <a href="https://github.com/smartroboticslab/mid-fusion"> code</a> 
                                        <!-- <a href="https://scholar.google.co.jp/citations?view_op=view_citation&hl=en&user=874PofoAAAAJ&sortby=pubdate&citation_for_view=874PofoAAAAJ:IjCSPb-OGe4C"
                                          aria-label="Google Scholar link" role="button"
                                          rel="external nofollow noopener" target="_blank">
                                          <img
                                            src="https://img.shields.io/badge/scholar-193-4285F4?logo=googlescholar&labelColor=beige"
                                            alt="193 Google Scholar citations"> </a> -->
                                      </td>
                                    </tr>

                                    <tr>
                                      <td style="padding:20px;width:25%;vertical-align:middle"><img
                                          src="pub/ral2017/ral2017.gif" width="97%" style="border-style: none"></td>
                                      <td style="padding:5px;width:75%;vertical-align:middle">
                                        <b><span class="papertitle">Spatio-temporal Video Completion in Spherical
                                            Image
                                            Sequences</span></b>
                                        <br>
                                        <b>Binbin Xu</b>, Sarthak Pathak, Hiromitsu Fujii, Atsushi Yamashita and
                                        Hajime
                                        Asama
                                        <br>
                                        <em>IEEE Robotics and Automation Letters (RA-L)</em>, Vol. 2, No. 4, pp.
                                        2032-2039, 2017
                                        <br>
                                        <a href="http://dx.doi.org/10.1109/LRA.2017.2718106">paper</a> /
                                        <a href="https://youtu.be/Y2oOumF8S3Q">video</a> 
                                        <!-- <a href="https://scholar.google.co.jp/citations?view_op=view_citation&hl=en&user=874PofoAAAAJ&sortby=pubdate&citation_for_view=874PofoAAAAJ:UeHWp8X0CEIC"
                                          aria-label="Google Scholar link" role="button"
                                          rel="external nofollow noopener" target="_blank">
                                          <img
                                            src="https://img.shields.io/badge/scholar-8-4285F4?logo=googlescholar&labelColor=beige"
                                            alt="8 Google Scholar citations"> </a> -->
                                      </td>
                                    </tr>
                                  </table>
                                </div>

                                <div class="subtitle_text">HONORS</div>
                                <ul>
                                  <li><a href="https://www.ieee-ras.org/publications/ra-l/ra-l-paper-awards">Best
                                      Paper
                                      Honorable
                                      Mention Award</a>, <br> IEEE Robotics and Automation Letters, 2021</li>
                                  <li><a href="data/master thesis award.pdf">Outstanding Master Thesis</a>, <br>
                                    Department of
                                    Precision Engineering, The University of Tokyo, 2017</li>
                                  <li><a
                                      href="data/JSME Fellow Award for Outstanding Young Engineers-plague.pdf">JSME
                                      Fellow Award
                                      for Outstanding Young Engineers</a>, <br> The Japan Society of Mechanical
                                    Engineers (JSME),
                                    2016</li>
                                  <li><a href="data/ICAM2015 Honorable Mention award.pdf">Best Paper Honorable
                                      Mention
                                      Award</a>,
                                    <br> 2015 JSME/RMD International Conference on Advanced Mechatronics, 2015
                                  </li>
                                </ul>


                                <div class="subtitle_text">Miscellaneous</div>
                                <ul>
                                  <li>Having spent wonderful years living in China, Japan, UK, and Canada, I am
                                    interested in exploring
                                    different cultures and talking with people from different backgrounds. I am
                                    fluent in Mandarin, English and Japanese.</li>
                                  <li>Associate Editors: ICRA (2024, 2025, 2026), IROS (2023, 2024, 2025)</li>
                                  <li>Reviewer Service: ICRA, IROS, CoRL, BMVC, TRO, RAL, JFR, TVCG, ... </li>
                                  <li>Outside of my research, I love travelling, hiking, climbing, SCUBA diving, and
                                    swimming.
                                  </li>
                                </ul>

                                <div style="padding-top: 50px;"> </div>

                            </div>
                        </div>
                    </div>

                    <!--

// gitter plugin
//    <script>
//          ((window.gitter = {}).chat = {}).options = {
//                  room: 'binbin-xu/room'
//                };
//    </script>
//    <script src="https://sidecar.gitter.im/dist/sidecar.v1.js" async defer></script>
-->

</body>

</html>
